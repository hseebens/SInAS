#   if (nchar(dat_match1$Country_ISO[1])==2) {
#     dat_match1 <- merge(regions,dat_match1,by.y="Country_ISO",by.x="ISO2",all.y=T)
#     dat_match1$Region_name_orig[!is.na(dat_match1$Region)] <- dat_match1$Region[!is.na(dat_match1$Region)]
#   } else if (nchar(dat_match1$Country_ISO[1])==3) {
#     dat_match1 <- merge(regions,dat_match1,by.y="Country_ISO",by.x="ISO3",all.y=T)
#     dat_match1$Region_name_orig[!is.na(dat_match1$Region)] <- dat_match1$Region[!is.na(dat_match1$Region)]
#   } else {
#     print("Warning: Provided country ISO codes do not match with implemented standard (ISO2, ISO3). Country names are used instead.")
#   }
# } else {
# ## or match names of 'dat' with region names of 'regions'
#   dat_match1 <- merge(dat_match1,regions,by.x="Region_name_orig",by.y="Region",all.x=T)
# }
## step 1: match names of 'dat' with region names of 'regions'
dat_match1 <- merge(dat_match1,regions,by.x="Region_name_orig",by.y="Region",all.x=T)
## step 3: match names by using keywords in 'regions
ind_keys <- which(!is.na(regions$keywords))
for (j in 1:length(ind_keys)){ # loop over rows with multiple keywords
if (any(grepl("; ",regions$keywords[ind_keys[j]]))){ # check if multiple keywords provided
keywords <- unlist(strsplit(regions$keywords[ind_keys[j]],"; "))
} else {
keywords <- regions$keywords[ind_keys[j]]
}
for (k in 1:length(keywords)){
ind_match <- grep(keywords[k],dat_match1$Region_name_orig)
dat_match1$Region_name_orig[ind_match] <- regions$Region[ind_keys[j]]
dat_match1$ISO2[ind_match]             <- regions$ISO2[ind_keys[j]]
}
}
d <- (unique(dat_match1[is.na(dat_match1$ISO2),c("Region_name_orig","Code")]))
d[order(d$Code),]
## identify input datasets based on file name "StandardSpec_....csv"
allfiles <- list.files("Output/")
inputfiles_all <- allfiles[grep("StandardSpecNames_",allfiles)]
inputfiles <- vector()
for (i in 1:length(inputfiles_all)){
inputfiles <- c(inputfiles,grep(FileInfo[i,"Dataset_brief_name"],inputfiles_all,value=T))
}
inputfiles <- inputfiles[!is.na(inputfiles)]
## load region table #################################################
regions <- read.xlsx("Config/AllRegionsList.xlsx",sheet=1,na.strings ="")
regions$keywords <- gsub("\\(","\\\\(",regions$keywords)
regions$keywords <- gsub("\\)","\\\\)",regions$keywords)
## loop over all data set ############################################
for (i in 1:length(inputfiles)){
dat <- read.table(paste0("Output/",inputfiles[i]),header=T,stringsAsFactors = F)
dat_match1 <- dat ## use another dat set for region matching to keep the original names
dat_match1$order <- 1:nrow(dat_match1)
dat_match1$Region_name_orig <- gsub("\\xa0|\\xc2", " ",dat_match1$Region_name_orig) # replace weird white space with recognised white space
dat_match1$Region_name_orig <- gsub("^\\s+|\\s+$", "",dat_match1$Region_name_orig) # trim leading and trailing whitespace
dat_match1$Region_name_orig <- gsub("  ", " ",dat_match1$Region_name_orig) # turn two spaces into one
dat_match1$Region_name_orig <- gsub(" \\(the\\)", "",dat_match1$Region_name_orig) # remove " (the)"
# ## step 0: if provided in FileInfo.xlsx, select R script to transform country names
# if (!is.na(FileInfo[i,"R_countrynames"])){ # check if R script name is provided
#   eval(bquote(source(.(paste0("R/",FileInfo[i,"R_countrynames"]))))) # load R script
#   exec <- gsub("\\.r","",FileInfo[i,"R_countrynames"])
#   dat_match1 <- eval(parse(text=paste0(substitute(exec,list(exec=exec)),"(dat_match1)")))
# }
# ## Step 1: Match country names by ISO codes (ISO2 or ISO3) if provideds (currently not working due to multiple ISO entries)
# if (!is.na(FileInfo[i,"Column_country_ISO"])){
#   if (nchar(dat_match1$Country_ISO[1])==2) {
#     dat_match1 <- merge(regions,dat_match1,by.y="Country_ISO",by.x="ISO2",all.y=T)
#     dat_match1$Region_name_orig[!is.na(dat_match1$Region)] <- dat_match1$Region[!is.na(dat_match1$Region)]
#   } else if (nchar(dat_match1$Country_ISO[1])==3) {
#     dat_match1 <- merge(regions,dat_match1,by.y="Country_ISO",by.x="ISO3",all.y=T)
#     dat_match1$Region_name_orig[!is.na(dat_match1$Region)] <- dat_match1$Region[!is.na(dat_match1$Region)]
#   } else {
#     print("Warning: Provided country ISO codes do not match with implemented standard (ISO2, ISO3). Country names are used instead.")
#   }
# } else {
# ## or match names of 'dat' with region names of 'regions'
#   dat_match1 <- merge(dat_match1,regions,by.x="Region_name_orig",by.y="Region",all.x=T)
# }
## step 1: match names of 'dat' with region names of 'regions'
dat_match1 <- merge(dat_match1,regions,by.x="Region_name_orig",by.y="Region",all.x=T)
## step 3: match names by using keywords in 'regions
ind_keys <- which(!is.na(regions$keywords))
for (j in 1:length(ind_keys)){ # loop over rows with multiple keywords
if (any(grepl("; ",regions$keywords[ind_keys[j]]))){ # check if multiple keywords provided
keywords <- unlist(strsplit(regions$keywords[ind_keys[j]],"; "))
} else {
keywords <- regions$keywords[ind_keys[j]]
}
for (k in 1:length(keywords)){
ind_match <- grep(keywords[k],dat_match1$Region_name_orig)
dat_match1$Region_name_orig[ind_match] <- regions$Region[ind_keys[j]]
dat_match1$ISO2[ind_match]             <- regions$ISO2[ind_keys[j]]
}
}
# d <- (unique(dat_match1[is.na(dat_match1$ISO2),c("Region_name_orig","Code")]))
# d[order(d$Code),]
# sort(unique(dat_match1[is.na(dat_match1$ISO2),]$Region))
## final merging of both data sets with standardised region names
dat_match1 <- dat_match1[order(dat_match1$order),]
if (!identical(dat_match1$Species_name_orig,dat$Species_name_orig)) stop("Data sets not sorted equally!")
dat$Region_name <- dat_match1$Region_name_orig
dat_regnames <- merge(dat,regions[,c("CountryID","ISO2","Region")],by.x="Region_name",by.y="Region",all.x=T)
## remove duplicated entries ##############
ind <- which(!duplicated(dat_regnames))
dat_regnames <- dat_regnames[ind,]
## keep only earliest first record
if (any(colnames(dat_regnames)=="First_record")){
oo <- order(dat_regnames$Region_name,dat_regnames$Species_name,dat_regnames$First_record) # sort ascending order
dat_regnames <- dat_regnames[oo,]
ind <- which(!duplicated(dat_regnames[,c("Region_name","Species_name")])) # identify duplicates (the first match is not counted, only the subsequent duplicates)
dat_regnames <- dat_regnames[ind,] # delete duplicates
}
## output ###############################################################################
missing <- dat_regnames$Region_name_orig[is.na(dat_regnames$CountryID)]
if (length(missing)>0){ # export missing country names
write.table(sort(unique(missing)),paste0("Output/MissingRegions_",FileInfo[i,"Dataset_brief_name"],".csv"))
}
dat_regnames <- dat_regnames[!is.na(dat_regnames$CountryID),]
write.table(dat_regnames,paste0("Output/StandardRegionNames_",FileInfo[i,"Dataset_brief_name"],".csv"))
}
getwd()
file.path("R")
file.path("R","runWorkflow")
file.path("R","runWorkflow.r")
library(here)
here("R","runWorkflow.r")
library(here)
file.path()
getwd()
file.path("R","PrepareDatasets.r")
################################################################################
### load other functions #######################################################
source(file.path("R","PrepareDatasets.r")) # preparing example data sets as input files
file.path("Config","DatabaseInfo.xlsx")
FileInfo <- read.xlsx(file.path("Config","DatabaseInfo.xlsx"),sheet=1)
library(rgbif) # for checking names, records and taxonomy; note: usage of rgbif may cause warnings like "Unknown or uninitalised column: " which is a bug. Can be ignored.
library(openxlsx)
FileInfo <- read.xlsx(file.path("Config","DatabaseInfo.xlsx"),sheet=1)
## load data set
data_name <- FileInfo[i,"File_name_to_load"]
i<-1
## load data set
data_name <- FileInfo[i,"File_name_to_load"]
data_name
file.path("Inputfiles/",data_name)
dat <- read.xlsx(file.path("Inputfiles",data_name),sheet=1)
file.path("Output","StandardColumns_",FileInfo[i,"Dataset_brief_name"],".csv")
file.path("Output",paste("StandardColumns_",FileInfo[i,"Dataset_brief_name"],".csv",sep=""))
## identify input datasets based on file name "StandardColumns_....csv"
allfiles <- list.files("Output/")
allfiles
## identify input datasets based on file name "StandardColumns_....csv"
allfiles <- list.files("Output")
allfiles
list.files("Output")
## identify input datasets based on file name "StandardColumns_....csv"
allfiles <- list.files("Output/")
allfiles
## identify input datasets based on file name "StandardColumns_....csv"
allfiles <- list.files("Output")
paste0(inputfiles[i])
## identify input datasets based on file name "StandardColumns_....csv"
allfiles <- list.files("Output")
inputfiles_all <- allfiles[grep("StandardColumns_",allfiles)]
inputfiles <- vector()
for (i in 1:length(inputfiles_all)){
inputfiles <- c(inputfiles,grep(FileInfo[i,"Dataset_brief_name"],inputfiles_all,value=T))
}
inputfiles <- inputfiles[!is.na(inputfiles)]
inputfiles
i
file.path("Output",paste0(inputfiles[i]))
i<-2
file.path("Output",paste0(inputfiles[i]))
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
dat
file.path("Output",paste0(StandardSpecNames_",FileInfo[i,"Dataset_brief_name"],".csv"))
file.path("Output",paste0("StandardSpecNames_",FileInfo[i,"Dataset_brief_name"],".csv"))
file.path("Output",paste0("MissingSpecNames_",FileInfo[i,"Dataset_brief_name"],".csv"))
file.path("Output","SpeciesNamesFullList.csv")
## identify input datasets based on file name "StandardSpec_....csv"
allfiles <- list.files("Output")
allfiles
## identify input datasets based on file name "StandardSpec_....csv"
allfiles <- list.files("Output")
inputfiles_all <- allfiles[grep("StandardSpecNames_",allfiles)]
inputfiles <- vector()
for (i in 1:length(inputfiles_all)){
inputfiles <- c(inputfiles,grep(FileInfo[i,"Dataset_brief_name"],inputfiles_all,value=T))
}
inputfiles <- inputfiles[!is.na(inputfiles)]
## load region table #################################################
regions <- read.xlsx(file.path("Config","AllRegionsList.xlsx"),sheet=1,na.strings ="")
regions
file.path("Config","AllRegionsList.xlsx")
file.path("Output",paste0(inputfiles[i]))
file.path("Output",paste0("StandardRegionNames_",FileInfo[i,"Dataset_brief_name"],".csv"))
file.path("Output",paste0("StandardRegionNames_",FileInfo[i,"Dataset_brief_name"],".csv"))
replacements <- read.xlsx(file.path("Config","Guidelines_FirstRecords.xlsx"))
replacements
file.path("Output",paste0(inputfiles[i]))
file.path("Output",paste0("NonNumericFirstRecords_",FileInfo[i,"Dataset_brief_name"],".csv"))
file.path("Output",paste0(inputfiles[i]))
file.path("Output",paste(outputfilename,version,".csv",sep=""))
interm_res <- list.files("Output")
interm_res
file.path("Config","DatabaseInfo.xlsx")
getwd()
getwd()
library(rgbif)
citation(rgbif)
citation("rgbif")
library(rgbif)
?name_backbone
graphics.off()
rm(list=ls())
## required libraries
library(rgbif) # for checking names, records and taxonomy; note: usage of rgbif may cause warnings like "Unknown or uninitalised column: " which is a bug. Can be ignored.
library(openxlsx)
## option for storing the intermediate and final output
outputfilename <- "AlienSpecies_MultipleDBs_Masterfile_vs" # name of final output file
version <- "2.1" # which version of the database are you going to produce? this will be attached to the end of 'outputfilename'
output <- T # shall intermediate results be stored to disk? (may overwrite existing files!)
################################################################################
### load other functions #######################################################
source(file.path("R","PrepareDatasets.r")) # preparing example data sets as input files
source(file.path("R","StandardiseSpeciesNames.r")) # standardising species names, requires GBIF connection, takes some time...
source(file.path("R","OverwriteSpeciesNames.r")) # replace species names with user-defined ones
source(file.path("R","StandardiseCountryNames.r")) # standardising country names
source(file.path("R","GetFirstRecord.r")) # standardising country names
source(file.path("R","MergeDatabases.r")) # combine data sets
source(file.path("R","CheckGBIFTax.r")) #function to check species names using GBIF taxonomy
################################################################################
################################################################################
######## Load data set table ###################################################
FileInfo <- read.xlsx(file.path("Config","DatabaseInfo.xlsx"),sheet=1)
if (nrow(FileInfo)==0) stop("No database information provided. Add information to Config/DatabaseInfo.xlsx.")
## load data set
data_name <- FileInfo[i,"File_name_to_load"]
dat <- read.xlsx(file.path("Inputfiles",data_name),sheet=1)
i<-1
## load data set
data_name <- FileInfo[i,"File_name_to_load"]
dat <- read.xlsx(file.path("Inputfiles",data_name),sheet=1)
dim(dat)
FileInfo[i,]
length(unique(dat$Region))
length(unique(dat$Taxon))
i<-1
i<-2
## load data set
data_name <- FileInfo[i,"File_name_to_load"]
dat <- read.xlsx(file.path("Inputfiles",data_name),sheet=1)
dim(dat)
FileInfo[i,"File_name_to_load"]
length(unique(dat$Region))
head(dat)
length(unique(dat$Species))
i<-3
FileInfo[i,"File_name_to_load"]
## load data set
data_name <- FileInfo[i,"File_name_to_load"]
dat <- read.xlsx(file.path("Inputfiles",data_name),sheet=1)
dim(dat)
length(unique(dat$Species))
str(dat)
length(unique(dat$tpl_input))
length(unique(dat$standardized_name))
length(unique(dat$tdwg4_name))
i<-4
FileInfo[i,"File_name_to_load"]
dim(dat)
data_name <- FileInfo[i,"File_name_to_load"]
dat <- read.xlsx(file.path("Inputfiles",data_name),sheet=1)
dim(dat)
str(dat)
length(unique(dat$Species))
length(unique(dat$CountryName))
i<-5
data_name <- FileInfo[i,"File_name_to_load"]
dat <- read.xlsx(file.path("Inputfiles",data_name),sheet=1)
FileInfo[i,"File_name_to_load"]
dim(dat)
length(unique(dat$country))
str(dat)
length(unique(dat$scientificName))
allfiles <- list.files("Output")
inputfiles_all <- allfiles[grep("StandardColumns_",allfiles)]
inputfiles <- vector()
for (i in 1:length(inputfiles_all)){
inputfiles <- c(inputfiles,grep(FileInfo[i,"Dataset_brief_name"],inputfiles_all,value=T))
}
inputfiles <- inputfiles[!is.na(inputfiles)]
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
## identify input datasets based on file name "StandardSpec_....csv"
allfiles <- list.files("Output")
inputfiles_all <- allfiles[grep("StandardSpecNames_",allfiles)]
inputfiles <- vector()
for (i in 1:length(inputfiles_all)){
inputfiles <- c(inputfiles,grep(FileInfo[i,"Dataset_brief_name"],inputfiles_all,value=T))
}
inputfiles <- inputfiles[!is.na(inputfiles)]
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
str(dat)
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
print(inputfiles[i])
print(dim(dat))
print(length(unique(dat$Species_name)))
print(length(unique(dat$Region_name_orig)))
i
i<-1
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
print(inputfiles[i])
print(dim(dat))
print(length(unique(dat$Species_name)))
print(length(unique(dat$Region_name_orig)))
i<-2
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
print(inputfiles[i])
print(dim(dat))
print(length(unique(dat$Species_name)))
print(length(unique(dat$Region_name_orig)))
i<-3
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
print(inputfiles[i])
print(dim(dat))
print(length(unique(dat$Species_name)))
print(length(unique(dat$Region_name_orig)))
i<-4
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
print(inputfiles[i])
print(dim(dat))
print(length(unique(dat$Species_name)))
print(length(unique(dat$Region_name_orig)))
## identify input datasets based on file name "StandardSpec_....csv"
allfiles <- list.files("Output")
inputfiles_all <- allfiles[grep("StandardRegionNames_",allfiles)]
inputfiles <- vector()
for (i in 1:length(inputfiles_all)){
inputfiles <- c(inputfiles,grep(FileInfo[i,"Dataset_brief_name"],inputfiles_all,value=T))
}
inputfiles <- inputfiles[!is.na(inputfiles)]
i<-1
for (i in 1:length(inputfiles)){
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
print(inputfiles[i])
print(dim(dat))
print(length(unique(dat$Species_name)))
print(length(unique(dat$Region_name_orig)))
}
## identify input datasets based on file name "StandardSpec_....csv"
allfiles <- list.files("Output")
inputfiles_all <- allfiles[grep("StandardIntroYear_",allfiles)]
inputfiles <- vector()
for (i in 1:length(inputfiles_all)){
inputfiles <- c(inputfiles,grep(FileInfo[i,"Dataset_brief_name"],inputfiles_all,value=T))
}
inputfiles <- inputfiles[!is.na(inputfiles)]
for (i in 1:length(inputfiles)){#
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
print(inputfiles[i])
print(dim(dat))
print(length(unique(dat$Species_name)))
print(length(unique(dat$Region_name_orig)))
}
file.path("Output",paste(outputfilename,version,".csv",sep=""))
dat <- read.table(paste("Output/",outputfilename,version,".csv",sep=""),stringsAsFactors = F,header=T)
dim(dat)
str(dat)
length(unique(dat$Species_author))
length(unique(dat$Species_names))
length(unique(dat$Species_name))
length(unique(dat$Region_name))
graphics.off()
rm(list=ls())
## required libraries
library(rgbif) # for checking names, records and taxonomy; note: usage of rgbif may cause warnings like "Unknown or uninitalised column: " which is a bug. Can be ignored.
library(openxlsx)
## option for storing the intermediate and final output
outputfilename <- "AlienSpecies_MultipleDBs_Masterfile_vs" # name of final output file
version <- "2.1" # which version of the database are you going to produce? this will be attached to the end of 'outputfilename'
output <- T # shall intermediate results be stored to disk? (may overwrite existing files!)
################################################################################
### load other functions #######################################################
source(file.path("R","PrepareDatasets.r")) # preparing example data sets as input files
source(file.path("R","StandardiseSpeciesNames.r")) # standardising species names, requires GBIF connection, takes some time...
source(file.path("R","OverwriteSpeciesNames.r")) # replace species names with user-defined ones
source(file.path("R","StandardiseCountryNames.r")) # standardising country names
source(file.path("R","GetFirstRecord.r")) # standardising country names
source(file.path("R","MergeDatabases.r")) # combine data sets
source(file.path("R","CheckGBIFTax.r")) #function to check species names using GBIF taxonomy
################################################################################
################################################################################
######## Load data set table ###################################################
FileInfo <- read.xlsx(file.path("Config","DatabaseInfo.xlsx"),sheet=1)
if (nrow(FileInfo)==0) stop("No database information provided. Add information to Config/DatabaseInfo.xlsx.")
## identify input datasets based on file name "StandardColumns_....csv"
allfiles <- list.files("Output")
inputfiles_all <- allfiles[grep("StandardColumns_",allfiles)]
inputfiles <- vector()
for (i in 1:length(inputfiles_all)){
inputfiles <- c(inputfiles,grep(FileInfo[i,"Dataset_brief_name"],inputfiles_all,value=T))
}
inputfiles <- inputfiles[!is.na(inputfiles)]
i<-4
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
print(inputfiles[i])
data_name <- FileInfo[i,"File_name_to_load"]
dat <- read.xlsx(file.path("Inputfiles",data_name),sheet=1)
print(inputfiles[i])
print(dim(dat))
dat_sub <- unique(dat[,c("standardized_name","author")])
tab <- table(dat_sub$standardized_name,dat_sub$author)
dim(tab)
ind <- as.data.frame(tab,stringsAsFactors = F)
head(ind)
ind <- ind[ind$Freq!=0,]
head(ind)
ind[ind$Freq>1,]
dim(dat_sub)
table(duplicated(dat_sub$standardized_name))
ind <- (duplicated(dat_sub$standardized_name))
dat_sub[ind,]
subset(dat,standardized_name=="Lotus tenuis")
subset(dat,author=="0")
i<-1
data_name <- FileInfo[i,"File_name_to_load"]
dat <- read.xlsx(file.path("Inputfiles",data_name),sheet=1)
print(inputfiles[i])
print(dim(dat))
source('~/Bioinvasion/IndicatorAliens/Workflow/UnifAlien/R/PrepareDatasets.r')
## identify input datasets based on file name "StandardSpec_....csv"
allfiles <- list.files("Output")
inputfiles_all <- allfiles[grep("StandardSpecNames_",allfiles)]
inputfiles <- vector()
for (i in 1:length(inputfiles_all)){
inputfiles <- c(inputfiles,grep(FileInfo[i,"Dataset_brief_name"],inputfiles_all,value=T))
}
inputfiles <- inputfiles[!is.na(inputfiles)]
regions <- read.xlsx(file.path("Config","AllRegionsList.xlsx"),sheet=1,na.strings ="")
regions$keywords <- gsub("\\(","\\\\(",regions$keywords)
regions$keywords <- gsub("\\)","\\\\)",regions$keywords)
regions$keywords <- tolower(regions$keywords) # set all region names to lower case for string matching
regions$Region_lower <- tolower(regions$Region) # set all region names to lower case for string matching
inputfiles
for (i in 1:length(inputfiles)){
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
print(inputfiles[i])
print(dim(dat))
print(length(unique(dat$Species_name_orig)))
print(length(unique(dat$Region_name_orig)))
}
i<-1
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
dim(dat)
dim(unique(dat))
str(dat)
head(dat)
## identify input datasets based on file name "StandardSpec_....csv"
allfiles <- list.files("Output")
inputfiles_all <- allfiles[grep("StandardSpecNames_",allfiles)]
inputfiles <- vector()
for (i in 1:length(inputfiles_all)){
inputfiles <- c(inputfiles,grep(FileInfo[i,"Dataset_brief_name"],inputfiles_all,value=T))
}
inputfiles <- inputfiles[!is.na(inputfiles)]
inputfiles
i<-1
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
print(inputfiles[i])
print(dim(dat))
print(length(unique(dat$Species_name_orig)))
print(length(unique(dat$Region_name_orig)))
## identify input datasets based on file name "StandardColumns_....csv"
allfiles <- list.files("Output")
inputfiles_all <- allfiles[grep("StandardColumns_",allfiles)]
inputfiles <- vector()
for (i in 1:length(inputfiles_all)){
inputfiles <- c(inputfiles,grep(FileInfo[i,"Dataset_brief_name"],inputfiles_all,value=T))
}
inputfiles <- inputfiles[!is.na(inputfiles)]
inputfiles
fullspeclist <- vector()
for (i in 1:length(inputfiles)){ # loop over inputfiles
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
print(inputfiles[i])
print(dim(dat))
print(length(unique(dat$Species_name_orig)))
print(length(unique(dat$Region_name_orig)))
}
i
data_name <- FileInfo[i,"File_name_to_load"]
dat <- read.xlsx(file.path("Inputfiles",data_name),sheet=1)
# print(inputfiles[i])
dim(dat)
str(dat)
# print(inputfiles[i])
# print(dim(dat))
print(length(unique(dat$scientificName)))
# print(length(unique(paste(dat$standardized_name,dat$author))))
# # print(length(unique(dat$CountryName)))
print(length(unique(dat$country)))
## identify input datasets based on file name "StandardColumns_....csv"
allfiles <- list.files("Output")
inputfiles_all <- allfiles[grep("StandardColumns_",allfiles)]
inputfiles <- vector()
for (i in 1:length(inputfiles_all)){
inputfiles <- c(inputfiles,grep(FileInfo[i,"Dataset_brief_name"],inputfiles_all,value=T))
}
inputfiles <- inputfiles[!is.na(inputfiles)]
dat <- read.table(file.path("Output",paste0(inputfiles[i])),header=T,stringsAsFactors = F)
print(inputfiles[i])
print(dim(dat))
print(length(unique(dat$Species_name_orig)))
print(length(unique(dat$Region_name_orig)))
dat$Region_name_orig
unique(dat$Region_name_orig)
